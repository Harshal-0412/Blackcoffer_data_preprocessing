{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b27d7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f4b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def positive_words_func():\n",
    "    with open(\"positive-words.txt\", \"r\") as file:\n",
    "        data = file.read()  # Read entire contents as a string\n",
    "        Positive_words = [word.lower() for word in data.split()]\n",
    "    return Positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d865be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def negative_words_func():\n",
    "    with open(\"negative-words.txt\", \"r\") as file:\n",
    "        data = file.read()  # Read entire contents as a string\n",
    "        Negative_words = [word.lower() for word in data.split()]\n",
    "    return Negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f54e3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def currencies_stopwords_func():\n",
    "    currencies_stopwords = []\n",
    "    keyword = \"|\"\n",
    "    count = 0\n",
    "    temp = \"\"\n",
    "    with open(\"StopWords_Currencies.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            for currencies in line:\n",
    "                if currencies in \"|\":\n",
    "                    currencies_stopwords.append(temp.strip().lower())\n",
    "                    temp = \"\"\n",
    "                    break\n",
    "                else:\n",
    "                    temp = temp + currencies\n",
    "    return currencies_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ffe3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def auditor_stopwords_func():\n",
    "    with open(\"StopWords_Auditor.txt\", \"r\") as file:\n",
    "        data = file.read()  # Read entire contents as a string\n",
    "        Auditors_stopwords = [word.lower() for word in data.split()]\n",
    "    return Auditors_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f825ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def stopwords_function(text, currencies_stopwords, Auditors_stopwords):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Tokenize the text (split into words)\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stop words from the list of words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [word for word in filtered_words if word.lower() not in currencies_stopwords]\n",
    "    filtered_words = [word for word in filtered_words if word.lower() not in Auditors_stopwords]\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f4b2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def Subjectivity_score(positive_score, negative_score, word_len):\n",
    "    # Subjectivity Score\n",
    "    subjectivity_score = (positive_score + negative_score)/ ((word_len) + 0.000001)\n",
    "    return subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb346d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polarity_score(positive_score, negative_score):\n",
    "    # Polarity Score\n",
    "    polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8185af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def score_count(filtered_words, words_list):\n",
    "    score = 0\n",
    "    for i in filtered_words:\n",
    "        if i in words_list:\n",
    "            score += 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dd394eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def fog_index_func(avg_sentence_len, perc_complex_words):\n",
    "    # fog index\n",
    "    fog_index = 0.4 * (avg_sentence_len + perc_complex_words)\n",
    "    return fog_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfb5f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def perc_complex_word_func(total_complex_words, total_words):\n",
    "    # percentage of complex words\n",
    "    perc_complex_words = total_complex_words / total_words\n",
    "    return perc_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aa9139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def avg_sentence_length(total_words, num_sentences):\n",
    "    # average number of words per sentence\n",
    "    # average sentence length\n",
    "    avg_sentence_len = total_words / num_sentences\n",
    "    return avg_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30a61c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def count_sentences_nltk(text):\n",
    "    # Check NLTK version (optional)\n",
    "    if nltk.__version__ >= '3.6':\n",
    "        print(\"Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\")\n",
    "        sentences = nltk.sent_tokenize(text)  # Recommended method for NLTK >= 3.6\n",
    "        return len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58e4cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def complex_word_count_func(words1):\n",
    "    # complex word count\n",
    "    total_complex_words = 0\n",
    "    for i in words1:\n",
    "        if words1[i][2] / words1[i][0] > 2:\n",
    "            total_complex_words += words1[i][0]\n",
    "    return total_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7d38f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def count_personal_pronoun(words1):\n",
    "    # count personal pronouns\n",
    "\n",
    "    # Define personal pronouns (case-insensitive)\n",
    "    personal_pronouns = [\n",
    "          \"I\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "          \"you\", \"your\", \"yours\", \"yourself\",\n",
    "          \"he\", \"him\", \"his\", \"himself\",\n",
    "          \"she\", \"her\", \"hers\", \"herself\",\n",
    "          \"it\", \"its\", \"itself\",\n",
    "          \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "          \"they\", \"them\", \"their\", \"theirs\", \"themselves\"\n",
    "      ]\n",
    "\n",
    "    total_personal_nouns = 0\n",
    "    for i in words1:\n",
    "        if i in personal_pronouns:\n",
    "            total_personal_nouns += words1[i][0]\n",
    "\n",
    "    return total_personal_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77d2da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def avg_word_len_func(total_char, total_words):\n",
    "    # average word length\n",
    "    avg_word_len = total_char / total_words\n",
    "    return avg_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2d41c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def total_count(words1):\n",
    "    # total characters\n",
    "    total_char = 0\n",
    "    total_words = 0\n",
    "    for i in words1: \n",
    "        total_words = total_words + words1[i][0]\n",
    "        total_char = total_char + (words1[i][0]*words1[i][1])\n",
    "    return [total_char, total_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ea12e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def count_total_words(word_tokens):\n",
    "    # Count total number of characters in each word\n",
    "    words1 = {}\n",
    "    punctuation1 = {}\n",
    "    vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
    "    for i in word_tokens:\n",
    "        if len(i) == 0:\n",
    "            continue\n",
    "        elif 'a' <= i[0] <= 'z' or 'A' <= i[0] <= 'Z':\n",
    "            if len(i) > 1 and i[0] == \"U\" and i[1] == \"S\":\n",
    "                pass\n",
    "            else:\n",
    "                i = i.lower()\n",
    "            if i not in words1:\n",
    "                words1[i] = [1, len(i), 0]\n",
    "            else:\n",
    "                words1[i][0] = words1[i][0] + 1\n",
    "            words1[i][2] += count_syllables(i)\n",
    "        else:\n",
    "            if i not in punctuation1:\n",
    "                punctuation1[i] = [1, len(i)]\n",
    "            else:\n",
    "                punctuation1[i][0] += 1\n",
    "    return words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8e1eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_syllable_count(words1, total_words):\n",
    "    syllable_count = 0\n",
    "    for i in words1:\n",
    "        syllable_count  = syllable_count + words1[i][2]\n",
    "    return syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c50d746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def count_syllables(text):\n",
    "  vowels = \"aeiou\"\n",
    "  exceptions = {\"es\": True, \"ed\": True}  # Words ending with these are not syllables\n",
    "\n",
    "  syllable_count = 0\n",
    "  last_char_vowel = False\n",
    "\n",
    "  for char in text:\n",
    "    if char in vowels:\n",
    "      # If the current character is a vowel and the last character wasn't,\n",
    "      # it's likely a new syllable (except for exceptions)\n",
    "      if not last_char_vowel:\n",
    "        syllable_count += 1\n",
    "        if char in exceptions and len(text) > 2 and text[-3] not in vowels:\n",
    "          # Handle exceptions like \"love\" and \"loved\" (but not \"lovedd\")\n",
    "          syllable_count -= 1\n",
    "      last_char_vowel = True\n",
    "    else:\n",
    "      last_char_vowel = False\n",
    "\n",
    "  return syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a379b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def tokenize_the_text(text):\n",
    "    # Tokenize the text into words\n",
    "    word_tokens = []\n",
    "    temp = \"\"\n",
    "    for i in text:\n",
    "        if 'a' <= i <= 'z' or 'A' <= i <= 'Z':\n",
    "            temp = temp + i\n",
    "        elif '0' <= i <= '9':\n",
    "            temp = temp + i\n",
    "        elif i == \" \":\n",
    "            word_tokens.append(temp)\n",
    "            temp = \"\"\n",
    "        else:\n",
    "            word_tokens.append(temp)\n",
    "            word_tokens.append(i)\n",
    "            temp = \"\"\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a42ae4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def web_crawler_func(URL):\n",
    "\n",
    "    # Send a GET request to the specified URL and store the response in 'resp'\n",
    "    resp = requests.get(URL)\n",
    "\n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    #print(soup)\n",
    "\n",
    "    entry_title = soup.find('h1', class_='entry-title')\n",
    "\n",
    "    header_title = entry_title.get_text()\n",
    "\n",
    "    specific_div = soup.find('div', class_='td-post-content tagdiv-type')\n",
    "\n",
    "    # Get the content of the specific <div>\n",
    "    specific_div_content = specific_div.get_text()\n",
    "\n",
    "\n",
    "    def remove_text_after_word(text, word):\n",
    "        index = text.find(word)\n",
    "        if index != -1:\n",
    "            return text[:index]\n",
    "        return text\n",
    "\n",
    "\n",
    "    specific_div_content = remove_text_after_word(specific_div_content, \"Blackcoffer Insights\")\n",
    "\n",
    "    text = header_title + specific_div_content\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ddee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk.sent_tokenize.PunktSentenceTokenizer (recommended)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11140\\1421133981.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your Excel file\n",
    "file_path = \"blackcoffer_dataset2.xlsx\"\n",
    "\n",
    "# Read the data from the first sheet (index 0) using pandas.read_excel()\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Create a output DataFrame\n",
    "output_data = {'URL id': [], 'POSITIVE SCORE': [], 'NEGATIVE SCORE': [], 'POLARITY SCORE': [], 'SUBJECTIVITY SCORE': [], 'AVG SENTENCE LENGTH': [], 'PERCENTAGE OF COMPLEX WORDS': [], 'FOG INDEX': [], 'AVG NUMBER OF WORDS PER SENTENCE': [], 'COMPLEX WORD COUNT': [], 'WORD COUNT': [], 'SYLLABLE PER WORD': [], 'PERSONAL PRONOUNS': [], 'AVG WORD LENGTH': []}\n",
    "df = pd.DataFrame(output_data)\n",
    "\n",
    "for i in range(len(data['URL'])):\n",
    "    text = web_crawler_func(data['URL'][i])\n",
    "    word_tokens = tokenize_the_text(text)\n",
    "    words1 = count_total_words(word_tokens)\n",
    "    total_char, total_words = total_count(words1)\n",
    "    avg_word_len = avg_word_len_func(total_char, total_words)\n",
    "    total_personal_nouns = count_personal_pronoun(words1)\n",
    "    total_complex_words = complex_word_count_func(words1)\n",
    "    num_sentences = count_sentences_nltk(text)\n",
    "    avg_sentence_len = avg_sentence_length(total_words, num_sentences)\n",
    "    perc_complex_words = perc_complex_word_func(total_complex_words, total_words)\n",
    "    fog_index = fog_index_func(avg_sentence_len, perc_complex_words)\n",
    "    syllable_count = final_syllable_count(words1, total_words)\n",
    "    Auditor_stopwords = auditor_stopwords_func()\n",
    "    currencies_stopwords = currencies_stopwords_func()\n",
    "    filtered_words = stopwords_function(text, currencies_stopwords, Auditor_stopwords)\n",
    "    Positive_words = positive_words_func()\n",
    "    Negative_words = negative_words_func()\n",
    "    positive_score = score_count(filtered_words, Positive_words)\n",
    "    negative_score = score_count(filtered_words, Negative_words)\n",
    "    subjectivity_score = Subjectivity_score(positive_score, negative_score, len(filtered_words))\n",
    "    polarity_score = Polarity_score(positive_score, negative_score)\n",
    "\n",
    "    new_row = {'URL id': data['URL_ID'],\n",
    "               'POSITIVE SCORE': positive_score,\n",
    "               'NEGATIVE SCORE': negative_score,\n",
    "               'POLARITY SCORE': polarity_score,\n",
    "               'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "               'AVG SENTENCE LENGTH': avg_sentence_len,\n",
    "               'PERCENTAGE OF COMPLEX WORDS': perc_complex_words,\n",
    "               'FOG INDEX': fog_index,\n",
    "               'AVG NUMBER OF WORDS PER SENTENCE': avg_sentence_len,\n",
    "               'COMPLEX WORD COUNT': total_complex_words, \n",
    "               'WORD COUNT': len(filtered_words),\n",
    "               'SYLLABLE PER WORD': syllable_count,\n",
    "               'PERSONAL PRONOUNS': total_personal_nouns,\n",
    "               'AVG WORD LENGTH': avg_word_len\n",
    "              }\n",
    "\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(\"output_data_harshal_jain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fcba1a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URL id': 'hello',\n",
       " 'POSITIVE SCORE': 41,\n",
       " 'NEGATIVE SCORE': 5,\n",
       " 'POLARITY SCORE': 0.7826086786389418,\n",
       " 'SUBJECTIVITY SCORE': 0.07044410402688499,\n",
       " 'AVG SENTENCE LENGTH': 15.512820512820513,\n",
       " 'PERCENTAGE OF COMPLEX WORDS': 0.1396694214876033,\n",
       " 'FOG INDEX': 6.260995973723247,\n",
       " 'AVG NUMBER OF WORDS PER SENTENCE': 15.512820512820513,\n",
       " 'COMPLEX WORD COUNT': 169,\n",
       " 'WORD COUNT': 653,\n",
       " 'SYLLABLE PER WORD': 1942,\n",
       " 'PERSONAL PRONOUNS': 69,\n",
       " 'AVG WORD LENGTH': 4.571074380165289}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
